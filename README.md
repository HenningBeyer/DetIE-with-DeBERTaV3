# Inference-of-More-Effective-Transformer-Encoders-in-the-Area-of-Open-Information-Extraction

This repository contains the used Code for replacing the BERT-encoder of [DetIE](https://github.com/sberbank-ai/DetIE) with the more effective variants of RoBERTa, ELECTRA, DeBERTa and DeBERTaV3.
This code is almost similar to the original code of DetIE and is only published for transparency as it includes only changes accounting for the different file structures when not using NVIDIA-Docker.

However, the corresponding German research paper is included as well as this actually relevant work that sets the new state of the art in the area of OIE by simply using newer BERT encoder variants is not planned to be officially published yet.
